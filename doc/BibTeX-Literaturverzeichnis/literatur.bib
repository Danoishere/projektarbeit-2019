@MANUAL{mirrorcle_userguide,
	AUTHOR = {Dr. Veljko Milanović and Abhishek Kasturi},
	TITLE = {Mirrorcle Technologies, Inc. PicoAmp 4.0 User Guide},
	ORGANIZATION = {Mirrorcle Technologies},
	YEAR = {2012},
	MONTH = {April}
}

@MANUAL{microchip_spi,
	ORGANIZATION = {Microchip Technology},
	TITLE = {Section 23. Serial Peripheral Interface (SPI)},
	YEAR = {2011}
}

@MANUAL{analog_devices_dac,
	ORGANIZATION = {Analog Devices},
	TITLE = {Quad, 12-/14-/16-Bit nanoDACs with 5 ppm/°C On-Chip Reference},
	YEAR = {2008}
}

@article{mnih2013playing,
	added-at = {2017-12-07T19:44:53.000+0100},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	biburl = {https://www.bibsonomy.org/bibtex/24140efabf4cab720d020e0e68f1451f6/lukasw},
	interhash = {78966703f649bae69a08a6a23a4e8879},
	intrahash = {4140efabf4cab720d020e0e68f1451f6},
	journal = {arXiv preprint arXiv:1312.5602},
	keywords = {atari final},
	timestamp = {2017-12-07T19:44:53.000+0100},
	title = {Playing atari with deep reinforcement learning},
	url = {https://arxiv.org/pdf/1312.5602.pdf},
	year = 2013
}

@article{a3c,
	Author = {Volodymyr Mnih and Adrià Puigdomènech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
	Title = {Asynchronous Methods for Deep Reinforcement Learning},
	Year = {2016},
	Eprint = {arXiv:1602.01783},
	Howpublished = {ICML 2016},
}

@article{marlsurvey,
	Author = {Pablo Hernandez-Leal and Bilal Kartal and Matthew E. Taylor},
	Title = {A Survey and Critique of Multiagent Deep Reinforcement Learning},
	Year = {2018},
	Eprint = {arXiv:1810.05587},
	Doi = {10.1007/s10458-019-09421-1},
}

@misc{marltraffica3c,
	Author = {Giulio Bacchiani and Daniele Molinari and Marco Patander},
	Title = {Microscopic Traffic Simulation by Cooperative Multi-agent Deep Reinforcement Learning},
	Year = {2019},
	Eprint = {arXiv:1903.01365},
}
	
	
@article {alphazero,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	doi = {10.1126/science.aar6404},
	publisher = {American Association for the Advancement of Science},
	abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.Science, this issue p. 1140; see also pp. 1087 and 1118The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/362/6419/1140},
	eprint = {https://science.sciencemag.org/content/362/6419/1140.full.pdf},
	journal = {Science}
}

@misc{hideandseek,
	Author = {Bowen Baker and Ingmar Kanitscheider and Todor Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
	Title = {Emergent Tool Use From Multi-Agent Autocurricula},
	Year = {2019},
	Eprint = {arXiv:1909.07528},
}

@inproceedings{policygradient,
	author = {Sutton, Richard S. and McAllester, David and Singh, Satinder and Mansour, Yishay},
	title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
	booktitle = {Proceedings of the 12th International Conference on Neural Information Processing Systems},
	series = {NIPS'99},
	year = {1999},
	location = {Denver, CO},
	pages = {1057--1063},
	numpages = {7},
	url = {http://dl.acm.org/citation.cfm?id=3009657.3009806},
	acmid = {3009806},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
} 


@Article{tdlearning,
	author="Sutton, Richard S.",
	title="Learning to predict by the methods of temporal differences",
	journal="Machine Learning",
	year="1988",
	month="Aug",
	day="01",
	volume="3",
	number="1",
	pages="9--44",
	abstract="This article introduces a class of incremental learning procedures specialized for prediction-that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, the new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference methods have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, temporal-difference methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage.",
	issn="1573-0565",
	doi="10.1007/BF00115009",
	url="https://doi.org/10.1007/BF00115009"
}


@thesis{explorationexploitation,
	author ="Lukas Rusch",
	title ="Exploration-Exploitation Trade-off in Deep Reinforcement Learning",
	submissiondate = "2018/08/31",
	date = "2018", % based on submissiondate
	urldate = "2019-11-11",
	year="2018",
	url = "https://pub.tik.ee.ethz.ch/students/2018-FS/BA-2018-15.pdf",
	type = "Bachelor's thesis",
	institution = "Distributed Computing Group	Computer Engineering and Networks Laboratory	ETH Zürich",
}
@ONLINE{aicrowd,
  URL = {https://www.aicrowd.com/challenges/flatland-challenge},
  LAST-VISITED = {2019-11-13}
}

@ONLINE{flatland_docu,
	URL = {http://flatland-rl-docs.s3-website.eu-central-1.amazonaws.com/},
	LAST-VISITED = {2019-12-01}
}

@ONLINE{flatland_spec,
	URL = {http://flatland-rl-docs.s3-website.eu-central-1.amazonaws.com/04_specifications.html/},
	LAST-VISITED = {2019-12-07}
}


@ONLINE{flatland_faq,
	URL = {https://gitlab.aicrowd.com/flatland/flatland/blob/master/FAQ_Challenge.md/},
	LAST-VISITED = {2019-12-09}
}

@ONLINE{python_gil,
	URL = {https://wiki.python.org/moin/GlobalInterpreterLock},
	LAST-VISITED = {2019-12-19}
}





@ONLINE{zhaw,
	URL = {https://www.zhaw.ch/en/university/},
	LAST-VISITED = {2019-11*-23}
}

@thesis{flatlandstephan,
	author ="Stephan Huschauer",
	title ="Multi-Agent based Traffic Routing for Railway Networks",
	date = "2019",
	type = "MSE VT2",
	publisher = "Unpublished",
	institution = "Institute of Applied Information Technology	ZHAW - Zurich University of Applied Sciences",
}

@InProceedings{multiagent_comp_a3c_dqn_etc,
	author="Gupta, Jayesh K.
	and Egorov, Maxim
	and Kochenderfer, Mykel",
	editor="Sukthankar, Gita
	and Rodriguez-Aguilar, Juan A.",
	title="Cooperative Multi-agent Control Using Deep Reinforcement Learning",
	booktitle="Autonomous Agents and Multiagent Systems",
	year="2017",
	publisher="Springer International Publishing",
	address="Cham",
	pages="66--83",
	abstract="This work considers the problem of learning cooperative policies in complex, partially observable domains without explicit communication. We extend three classes of single-agent deep reinforcement learning algorithms based on policy gradient, temporal-difference error, and actor-critic methods to cooperative multi-agent systems. To effectively scale these algorithms beyond a trivial number of agents, we combine them with a multi-agent variant of curriculum learning. The algorithms are benchmarked on a suite of cooperative control tasks, including tasks with discrete and continuous actions, as well as tasks with dozens of cooperating agents. We report the performance of the algorithms using different neural architectures, training procedures, and reward structures. We show that policy gradient methods tend to outperform both temporal-difference and actor-critic methods and that curriculum learning is vital to scaling reinforcement learning algorithms in complex multi-agent domains.",
	isbn="978-3-319-71682-4"
}


@article{vehicle_rescheduling_problem,
	title = "The vehicle rescheduling problem: Model and algorithms",
	abstract = "When a vehicle on a scheduled trip breaks down, one or more vehicles need to be rescheduled to serve the customers on that trip with minimum operating and delay costs. The problem of reassigning vehicles in real-time to this cut trip as well as to other scheduled trips with given starting and ending times, is referred to as the vehicle rescheduling problem (VRSP). This paper considers modeling, algorithmic, and computational aspects of the single-depot VRSP. The paper formulates a model for this problem and develops several fast algorithms to solve it, including parallel synchronous auction algorithms. The concept of the common feasible network (CFN) is introduced to find a good set of initial {"}prices{"} for speeding up the auction algorithm. Computational experiments on randomly generated problems are described. Computational results show that, for small problems, all of the developed algorithms demonstrate very good computational performances. For large problems, parallel CFN-based auction algorithms provide the optimal solution with much smaller computation times.",
	keywords = "Auction algorithm, Parallel processing, Rescheduling, Vehicle scheduling",
	author = "Li, {Jing Quan} and Pitu Mirchandani and Denis Borenstein",
	year = "2007",
	month = "10",
	doi = "10.1002/net.20199",
	language = "English (US)",
	volume = "50",
	pages = "211--219",
	journal = "Networks",
	issn = "0028-3045",
	publisher = "Wiley-Liss Inc.",
	number = "3",
}

@inproceedings{Ephrati1993MultiAgentPA,
	title={Multi-Agent Planning as the Process of Merging Distributed Sub-plans},
	author={Eithan Ephrati and Jeffrey S. Rosenschein},
	year={1993}
}


@ONLINE{aicrowd_startpage,
	URL = {https://www.aicrowd.com/},
	LAST-VISITED = {2019-12-17}
}

@article{entropy_shannon,
	abstract = {The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.},
	added-at = {2019-11-20T15:05:21.000+0100},
	author = {Shannon, Claude Elwood},
	biburl = {https://www.bibsonomy.org/bibtex/26fa16c731d4668b2b4ba27f141e2b2fe/rarefier},
	description = {A mathematical theory of communication - Nokia Bell Labs Journals & Magazine},
	doi = {10.1002/j.1538-7305.1948.tb01338.x},
	interhash = {754130207906fcec16a53d330eeff348},
	intrahash = {6fa16c731d4668b2b4ba27f141e2b2fe},
	issn = {0005-8580},
	journal = {The Bell System Technical Journal},
	keywords = {information_theory mathematics},
	month = {July},
	number = 3,
	pages = {379-423},
	timestamp = {2019-11-21T16:07:09.000+0100},
	title = {A mathematical theory of communication},
	url = {https://ieeexplore.ieee.org/document/6773024},
	volume = 27,
	year = 1948
}





