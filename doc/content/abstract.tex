%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  _____   ____  _____                                          %
% |_   _| /  __||  __ \    Institute of Computitional Physics   %
%   | |  |  /   | |__) |   Zuercher Hochschule Winterthur       %
%   | |  | (    |  ___/    (University of Applied Sciences)     %
%  _| |_ |  \__ | |        8401 Winterthur, Switzerland         %
% |_____| \____||_|                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Project     : LaTeX doc Vorlage für Windows ProTeXt mit TexMakerX
% Title       : 
% File        : abstract.tex Rev. 00
% Date        : 23.4.12
% Author      : Remo Ritzmann
% Feedback bitte an Email: remo.ritzmann@pfunzle.ch
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty}
\chapter*{Zusammenfassung}\label{chap.zusammenfassung}

%1. Einleitung («Problemstellung»): Definiert die Problematik und begründet die Relevanz der Arbeit. Die Situation (eine problematische Situation oder technische Problematik) und die wissenschaftliche/fachliche Untersuchungs-Fragestellung (folgt logischer- weise aus der festgestellten Problematik) werden kurz beschrieben.
Aufgrund der steigenden Anzahl an Pendlern in den letzen Jahren hat die Verdichtung des Schienenverkehrs auf dem bestehenden Schienennetz der Schweizerischen Bundesbahn (SBB) eine hohe Priorität.
Eine eben so hohe Relevanz hat die Verminderung der Verspätungen durch technische Störrungen an der Infrastruktur oder an Zügen.
Daher befassen wir uns in dieser Arbeit mit der Steuerung komplexer Zugverkehrssysteme mittel Maschine Learning, genauer gesagt Reinforcement Learning (RL).\\
%2. Methodische Einordnung der Arbeit: Art, Datenbasis und Ziel der Arbeit. Die Untersuchungsmethode (Umfrage, Analyse, Versuch, Test etc.), das untersuchte „Material“ und das dabei verfolgte Ziel wird thematisiert.
Diese Projektarbeit findet indirekt mit der Schweizerischen Bundesbahn statt, da sie eine Challenge zu diesem Thema auf AICrowd ausgeschrieben haben.
Die SBB stellt in Zusammenarbeit mit AICrowd die Simulationsumgebung Flatland zur Verfügung. Mittels Flatland kann ein komplexes Schienennetz simuliert werden, mit welchem die durch künstliche Intelligenz gesteuerten Züge interagieren können.
Beim zu lösenden Problem handelt es sich um ein kollaboratives Multi-Agent Problem. Das Ziel ist, dass alle Züge so schnell wie möglich an ihrem Zielbahnhof ankommen und sich nicht gegenseitig blockieren. Wenn es zu einer Blockade kommt, zieht dies meist eine Kettenreaktion mit sich. Folglich kommen etliche Züge erst gar nicht an.
%3. Vorgehen («Problembehandlung»): Informiert über das Vorgehen und über die Untersuchungsanlage.
Wir implementierten unseren Lösungsansatz mit dem Asynchronous Advantage Actor Critic Algorithmus (A3C), einer der derzeit besten RL-Algorithmen, welcher verteiltes Lernen ermöglicht.
Nach der ersten lauffähigen Version erweiterten wir unseren Stand nach und nach mit unterschiedlichen Features wie Long short-term memory, Curriculum Learning oder verteiltem Lernen.
Unsere Änderungen kontrollierten wir stetig mit Experimenten um Fortschritt zu gewährleisten.
%4. Ergebnis («Problemlösung»): Beschreibt die wichtigsten Resultate, Erkenntnisse, offenen Fragen. Die Ergebnisse werden aufgeführt und dabei wird auf die unter 1. auf- geführte Fragestellung Bezug genommen (konnte sie beantwortet werden, gibt es of- fene Punkte?).
Durch das Hinzufügen von unterschiedlichen Features konnten wir ein Resultat von 48.9\% in Runde 1 erzielen.
In Runde 2 veränderten wir den Aktionsraum, was die Anzahl Abfragen vom neuronalen Netzwerk deutlich reduzierte. Dies verbesserte die Laufzeit sowie den Lernfortschritt stark.
Durch den Einsatz von Regeln, welche spezielle Fälle verhindern, konnten wir eine Ankunftwahrscheinlichkeit von 29.1\% erreichen, was aktuell dem 4. Platz entspricht von insgesammt 24 teilnehmenden Teams auf AICrowd.
%TODO: Aktionsraum okay?
\newpage
\thispagestyle{empty}
\chapter*{Abstract}\label{abstract}
Due to the increasing number of commuters in recent years, the consolidation of rail traffic on the Swiss Federal Railways (SBB) existing rail network has a high priority.
The reduction of delays caused by technical faults in the infrastructure or on trains is just as relevant.
Therefore, in this thesis we deal with the control of complex train traffic systems by means of machine learning, or more precisely reinforcement learning (RL).
Swiss Federal Railways is indirectly our project partner, as they have put out a challenge on this topic on AICrowd.
SBB provides the simulation environment Flatland in cooperation with AICrowd. Flatland can be used to simulate a complex rail network with which trains controlled by artificial intelligence can interact.
The problem to be solved is a collaborative multi-agent problem. The goal is that all trains arrive at their destination station as quickly as possible and do not block each other. When a blockade occurs, it usually involves a chain reaction. As a result, many trains do not arrive at all.
We implemented our solution with the Asynchronous Advantage Actor Critic Algorithm (A3C), one of the currently best RL algorithms, which enables distributed learning.
After the first executable version, we gradually expanded our stand with various features such as long short-term memory, curriculum learning or distributed learning.
We constantly controlled our changes with experiments to ensure progress.
By adding different features we were able to achieve a result of 48.9\% in round 1.
In round 2 we changed the action space, which significantly reduced the number of queries to the neural network. This greatly improved the runtime and learning progress.
By using rules that prevent special cases, we were able to achieve an arrival probability of 29.1\%, which currently corresponds to 4th place out of 24 participating teams on AICrowd.


\chapter*{Preface}\label{preface}
We would like to give special thanks to:
\begin{itemize}
    \item Andreas Weiler and Thilo Stadelmann for their great support during this work, for their helpful tips and for pushing us into the right direction.\\
    We are grateful for the opportunity to dive deep into the field of reinforcement learning as part of this project.
    \item Remo Maurer for being very generous with providing computing infrastructure, especially the infrastructure test server.
\end{itemize}

