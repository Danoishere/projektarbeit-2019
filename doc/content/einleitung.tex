\chapter{Introduction}\label{chap.einleitung}
\section{Baseline}\label{baseline}
\begin{itemize}
\item Nennt bestehende Arbeiten/Literatur zum Thema -> Literaturrecherche
\item Stand der Technik: Bisherige Lösungen des Problems und deren Grenzen
\item (Nennt kurz den Industriepartner und/oder weitere Kooperationspartner und dessen/deren Interesse am Thema Fragestellung)
\end{itemize}
This work explores a real world usage of deep reinforcment learning (RL) for controlling train traffic in a complex railway system.
As part of the flatland challenge, a contest created by the Swiss Federal Railways (SBB AG) and the crowdsourcing platform AICrowd \cite{aicrowd}, we try to improve the performance of RL based train guidance and rescheduling. The goal of the challenge is to successfully guide all trains to their assigned target stations without getting stuck. This is challenging because a single wrong decision can cause a chain reaction that makes it impossible for many other trains to sucessfully reach their destinations. This endeavour is further complicated by trains with different speed profiles and the possibility of malfunctioning trains. In the words of SBB and AICrowd, the challenge is described as follows \cite{aicrowd}:
\begin{quote}
	The Flatland Challenge is a competition to foster progress in multi-agent reinforcement learning for any re-scheduling problem (RSP). The challenge addresses a real-world problem faced by many transportation and logistics companies around the world (such as the Swiss Federal Railways, SBB. Different tasks related to RSP on a simplified 2D multi-agent railway simulation must be solved. Your contribution may shape the way modern traffic management systems (TMS) are implemented not only in railway but also in other areas of transportation and logistics. This will be the first of a series of challenges related to re-scheduling and complex transportation systems.
\end{quote}
The challenge consists of two parts \cite{aicrowd}.  
\begin{itemize}
	\item Part 1 includes avoiding conflicts with multiple trains (agents) on a given environment. The difficulty thereby is, that the layout of the environment is not known upfront.
	\item Part 2 aims to optimize train traffic which includes trains with different speed profiles, malfunctioning trains, less switchover facilities and in general more scheduled trains in a shorter time.
\end{itemize}
This work is based on the work of Stefan Huschauer \cite{flatlandstephan} and further investigates on the idea to use the asynchronous advantage actor critic algorithm (A3C) \cite{a3c}, a state of the art RL algorithm, to solve the task.
Besides the work of S. Huschauer, this work is also influenced by the work of Bacchiani, Molinari and Patander \cite{marltraffica3c}. That work also aims to apply the A3C algorithm in a cooperative multi agent environment and investigates communication free cooperation.
Unlike the flatland challenge, the goal of this work is to cooperate on a road traffic environment. By applying the A3C algorithm, the work shows that it is possible learn cooperation by treating the other agents as part of the environment. Both the works of Bacchiani, Molinari and Patander as well as the work of S. Huschauer use a shared policy for all acting agents.

%He used the first version of Flatland to evaluate his models and got a total score of 24.7\% in a local evaluation.%TODO: check
%He trained his model with 2 to 10 agents with a field of view of 10*10. %TODO: fertigmachen


\section{Goal of this work}\label{zielsetzung}
\begin{itemize}
\item Formuliert das Ziel der Arbeit
\item Verweist auf die offizielle Aufgabenstellung des/der Dozierenden im Anhang
\item (Pflichtenheft, Spezifikation)
\item (Spezifiziert die Anforderungen an das Resultat der Arbeit)
\item (Übersicht über die Arbeit: stellt die folgenden Teile der Arbeit kurz vor)
\item (Angaben zum Zielpublikum: nennt das für die Arbeit vorausgesetzte Wissen)
\item (Terminologie: Definiert die in der Arbeit verwendeten Begriffe)
\end{itemize}
%Comment: Explore ths use of A3C RL Learning in am cooperative multi agent env.
The aim of the work is to explore the use of the A3C algorithm in the flatland multi agent environment and to improve on the approach of S. Huschauer \cite{flatlandstephan}.
This work is targeted towards an audience with a brief understanding of deep reinforcement learning. A basic introduction into the topic is given in \autoref{reinforcementlearning}.
Also, the details of the flatland environment can be found in \autoref{flatland_intro}. For a deeper understanding of the complex flatland environment, it is recommended to study the flatland documentation and specification \cite{flatland_docu} as well as the official flatland introduction \cite{aicrowd}.


\section{Zielsetzung / Aufgabenstellung / Anforderungen}\label{zielsetzung}

%Vorwissen


%Terminologie hier oder Verweis auf Glossar?
