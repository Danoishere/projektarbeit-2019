\chapter{Introduction}\label{chap.einleitung}
\section{Baseline}\label{baseline}
This work explores a real world usage of multi agent reinforcement learning (MARL) for controlling train traffic in a complex railway system.
As part of the Flatland challenge, a contest created by the Swiss Federal Railways (SBB) and the crowdsourcing platform AICrowd \cite{aicrowd}, we try to improve the performance of RL based train guidance and rescheduling. The goal of the challenge is to successfully guide all trains to their assigned target stations in a simulated environment called Flatland environment.
This is challenging because a single wrong decision can cause a chain reaction that makes it impossible for many other trains to successfully reach their destinations. The endeavor is further complicated by trains with different speed profiles and the possibility of malfunctioning trains. In the words of SBB and AICrowd, the challenge is described as follows \cite{aicrowd}:
\begin{quote}
	The Flatland Challenge is a competition to foster progress in multi-agent reinforcement learning for any re-scheduling problem (RSP). The challenge addresses a real-world problem faced by many transportation and logistics companies around the world (such as the Swiss Federal Railways, SBB). Different tasks related to RSP on a simplified 2D multi-agent railway simulation must be solved. Your contribution may shape the way modern traffic management systems (TMS) are implemented not only in railway but also in other areas of transportation and logistics. This will be the first of a series of challenges related to re-scheduling and complex transportation systems.
\end{quote}
The challenge consists of two parts \cite{aicrowd}.  
\begin{itemize}
	\item Part 1 includes avoiding conflicts with multiple trains (agents) on a given environment. The difficulty thereby is, that the layout of the environment is not known upfront.
	\item Part 2 aims to optimize train traffic which includes trains with different speed profiles, malfunctioning trains, less switchover facilities and in general more scheduled trains in a shorter time.
\end{itemize}
This work is based on the work of Stefan Huschauer \cite{flatlandstephan} and further investigates on the idea to use the asynchronous advantage actor critic algorithm (A3C) \cite{a3c}, a state of the art RL algorithm, to solve the task.
Besides the work of S. Huschauer, this work is also related to the work of Bacchiani, Molinari and Patander \cite{marltraffica3c}. Their work also aims to apply the A3C algorithm in a cooperative multi-agent environment and investigates communication free cooperation.
Unlike the Flatland challenge, the goal of this work is to cooperate on a road traffic environment. By applying the A3C algorithm, the work shows that it is possible learn cooperation by treating the other agents as part of the environment. Both the works of Bacchiani, Molinari and Patander as well as the work of S. Huschauer use a shared policy for all acting agents.

\section{Goal of this work}\label{zielsetzung}
%Comment: Explore ths use of A3C RL Learning in am cooperative multi agent env.
The aim of the work is to explore the use of the A3C algorithm in the Flatland multi-agent environment and to improve on the approach of S. Huschauer \cite{flatlandstephan}.\\
While it could be argued that there are better ways to solve the given problem than RL, we mainly focus on pure RL but give in the \autoref{chap.resultate} our intuition on how the explored approach could work together with other techniques to improve its success.
This work is targeted towards an audience with a brief understanding of deep reinforcement learning. A basic introduction into the topic is given in \autoref{reinforcementlearning}. This introduction is focused on the techniques required to understand the applied A3C algorithm and does not cover the whole field of RL.
Also, the details of the Flatland environment can be found in \autoref{flatland_intro}. For a deeper understanding of the complex Flatland environment, it is recommended to study the Flatland documentation and specification \cite{flatland_docu} as well as the official Flatland introduction \cite{aicrowd}.

\section{Iterative Work Approach}\label{basic_cons}
We divide this work into 4 main sections:
\begin{itemize}
	\item \textbf{\nameref{chap.basic_implementation}:} In this section, we have a look at our basic implementation to solve the Flatland challenge. Also, we shortly describe the technologies used.
	\item \textbf{\nameref{chap.experiment}:} We identify parts of the implementation that offer room for improvement. To verify our work, we create experiments and analyse them afterwards.
	\item \textbf{\nameref{chap.resultate}:} We discuss ouf final solution that we submit in the Flatland challenge for both round 1 and round 2.
	\item \textbf{\nameref{chap.diskussion}:} Here we discuss parts of our solution that would need further improvement.
\end{itemize}
We take the idea of using the A3C algorithm to solve the Flatland problem and try various modifications in an attempt to improve its performance. We proceed by giving an idea, what we want to achieve, followed by an experiment setup and an experiment analysis to either prove or disprove our hypothesis. We do this in an iterative manner, to gradually come closer to a well-performing solution for Flatland.\\
In our experiments, we focus exclusively on Flatland round 2. While we compare our solution for round 1 in \autoref{chap.resultate}, all technical improvements have also become part of our solution for round 2.
