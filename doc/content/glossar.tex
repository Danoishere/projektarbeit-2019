%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  _____   ____  _____                                          %
% |_   _| /  __||  __ \    Institute of Computitional Physics   %
%   | |  |  /   | |__) |   Zuercher Hochschule Winterthur       %
%   | |  | (    |  ___/    (University of Applied Sciences)     %
%  _| |_ |  \__ | |        8401 Winterthur, Switzerland         %
% |_____| \____||_|                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Project     : LaTeX doc Vorlage f√ºr Windows ProTeXt mit TexMakerX
% Title       : 
% File        : glossar.tex Rev. 00
% Date        : 23.4.12
% Author      : Remo Ritzmann
% Feedback bitte an Email: remo.ritzmann@pfunzle.ch
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Glossary}\label{section.glossar}
%\addcontentsline{toc}{section}{(Glossar)}

\begin{longtable}{|m{3cm}|m{11cm}|}\hline
\rowcolor{gray} \textbf{Term}&
Explanation \\ 
\hline

\textbf{Agent}&
An agent is the entity that needs to take a decision, based on its current situation. In this work, an agent usually corresponds with a train.\\
\hline

\textbf{AICrowd}&
A crowdsourcing platform for competitions about machine learning \cite{aicrowd_startpage}. The Flatland challenge has been partly organized by AICrowd.\\ 
\hline

\textbf{Episode}&
The cycle of taking actions and receiving a new state until the environment has reached a terminal state. \\ 
\hline

\textbf{Entropy}&
A term for how much randomness can be expected from a variable \cite{entropy_shannon}.
For a single variable an entropy of 1 corresponds to complete randomness, and entropy of 0 corresponds to complete certainty.
Abbreviated as $\mathcal{H}$.\\ 
\hline

\textbf{Environment}&
A system for reinforcement learning agents to learn. In this work, an environment is usually a Flatland rail simulation.
\hline

\textbf{Policy}&
The rules used to decide which action to take, based on a given state. Abbreviated as $\pi$.\\ 
\hline

\textbf{Reward}&
The scalar value an agent can receive in a reinforcement learning task. Positive for good actions, negative for bad ones.\\ 
\hline

\textbf{Hypertext Transfer Protocol}&
Stateless protocol to transfer data between different applications on the application layer. \\ \hline

\textbf{ZLib}&
Python module to compress and decompress data. \\ \hline


%Check the following terms:
%Flatland
%Deep Q-Networks



\caption{Glossary definitions}
\label{tab:glossar}
\end{longtable}
\clearpage

\section{Abbreviations}\label{section:abkuerzungsverzeichnis}
%\addcontentsline{toc}{section}{(Abkuerzungsverzeichnis)}


\begin{longtable}{|m{3cm}|m{11cm}|}\hline	
	\rowcolor{gray} \textbf{Abbr}&
	Abbreviation \\ \hline

	\textbf{A3C}&
	Asynchronous Advantage Actor Critic Algorithm \\ \hline

	\textbf{DQN}&
	Deep Q-Network \\ \hline

	\textbf{HTTP}&
	Hypertext Transfer Protocol \\ \hline

	\textbf{LSTM}&
	Long short-term memory \\ \hline

	\textbf{MARL}&
	Multi agent reinforcement learning \\ \hline

	\textbf{RL}&
	Reinforcement learning \\ \hline

	\textbf{RSP}&
	Re-scheduling problem \\ \hline

	\textbf{TMS}&
	Traffic management systems \\ \hline

	\textbf{TRPO}&
	Trust region policy optimization \\ \hline

\caption{Abbreviations}
\label{tab:abkuerzungsverzeichnis}
\end{longtable}
